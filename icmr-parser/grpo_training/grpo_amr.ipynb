{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6fa8c5",
   "metadata": {},
   "source": [
    "# GRPO Fine-tuning for AMR Prescription Validation\n",
    "\n",
    "This notebook implements Group Relative Policy Optimization (GRPO) for fine-tuning language models on AMR (Antimicrobial Resistance) prescription validation tasks.\n",
    "\n",
    "**GRPO** is a reinforcement learning method that optimizes language models by:\n",
    "- Generating multiple outputs per prompt\n",
    "- Computing rewards for each output using LLM-as-a-Judge\n",
    "- Using group-relative advantages for stable optimization\n",
    "- Updating the model to favor high-reward outputs\n",
    "\n",
    "**Dataset**: ICMR 2025 Antimicrobial Treatment Guidelines\n",
    "**Task**: Validate prescriptions with step-by-step clinical reasoning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae1ccc1",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Run this cell first!\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if running in Colab\n",
    "if \"COLAB_\" in \"\".join(os.environ.keys()):\n",
    "    print(\"ðŸ”§ Installing packages for Google Colab...\")\n",
    "    !pip install -q unsloth bitsandbytes accelerate peft trl transformers datasets\n",
    "else:\n",
    "    print(\"ðŸ”§ Installing packages for local environment...\")\n",
    "    !pip install -q unsloth transformers datasets groq pydantic tqdm aiohttp nest-asyncio\n",
    "\n",
    "print(\"âœ… Installation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8417a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import hashlib\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple, Any\n",
    "from datasets import Dataset, load_dataset\n",
    "from unsloth import FastLanguageModel\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"âœ… All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28253c3",
   "metadata": {},
   "source": [
    "## 2. Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf53fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "OUTPUT_DIR = \"./grpo_amr_model\"\n",
    "\n",
    "# ============================================================================\n",
    "# EVALUATION API CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# IMPORTANT: Set your Supabase Edge Function URL here\n",
    "# After deploying: supabase functions deploy evaluate-prescription\n",
    "API_BASE_URL = \"https://your-project.supabase.co/functions/v1/evaluate-prescription\"\n",
    "\n",
    "# Priority metrics for training (faster, focused on key aspects)\n",
    "PRIORITY_METRICS = ['clinical_accuracy', 'guideline_adherence', 'reasoning_completeness']\n",
    "\n",
    "# All metrics for comprehensive evaluation\n",
    "ALL_METRICS = [\n",
    "    'clinical_accuracy',\n",
    "    'guideline_adherence',\n",
    "    'reasoning_completeness',\n",
    "    'safety_awareness',\n",
    "    'decision_appropriateness',\n",
    "    'reference_accuracy'\n",
    "]\n",
    "\n",
    "# Reward weights for each metric (must sum to 1.0)\n",
    "REWARD_WEIGHTS = {\n",
    "    'clinical_accuracy': 0.25,\n",
    "    'guideline_adherence': 0.25,\n",
    "    'reasoning_completeness': 0.20,\n",
    "    'safety_awareness': 0.15,\n",
    "    'decision_appropriateness': 0.10,\n",
    "    'reference_accuracy': 0.05\n",
    "}\n",
    "\n",
    "# API Configuration\n",
    "API_CONFIG = {\n",
    "    \"max_concurrent_requests\": 50,\n",
    "    \"timeout_seconds\": 45,\n",
    "    \"max_retries\": 3,\n",
    "    \"retry_delay\": 2.0,\n",
    "    \"use_cache\": True,\n",
    "}\n",
    "\n",
    "# Evaluation frequency (evaluate every N training steps)\n",
    "EVAL_FREQUENCY = 10\n",
    "\n",
    "# ============================================================================\n",
    "# GRPO HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "GRPO_CONFIG = {\n",
    "    \"num_generations_per_prompt\": 2,\n",
    "    \"batch_size\": 2,\n",
    "    \"learning_rate\": 5e-6,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"max_length\": 1024,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.95,\n",
    "    \"kl_coef\": 0.05,\n",
    "    \"clip_range\": 0.2,\n",
    "    \"vf_coef\": 0.1,\n",
    "    \"eval_frequency\": EVAL_FREQUENCY,\n",
    "    \"use_priority_metrics\": True,\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# UNSLOTH CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "MAX_SEQ_LENGTH = 2048\n",
    "LOAD_IN_4BIT = True\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "LORA_DROPOUT = 0\n",
    "LORA_TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "\n",
    "print(\"âœ… Configuration loaded successfully!\")\n",
    "print(f\"ðŸ“ API Base URL: {API_BASE_URL}\")\n",
    "print(f\"ðŸŽ¯ Using Metrics: {'PRIORITY (3 metrics)' if GRPO_CONFIG['use_priority_metrics'] else 'ALL (6 metrics)'}\")\n",
    "print(f\"ðŸ“Š Evaluation Frequency: Every {EVAL_FREQUENCY} steps\")\n",
    "print(f\"âš¡ Batch Size: {GRPO_CONFIG['batch_size']}\")\n",
    "print(f\"ðŸ”¢ Generations per prompt: {GRPO_CONFIG['num_generations_per_prompt']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3facdbf9",
   "metadata": {},
   "source": [
    "## 3. Load Dataset\n",
    "\n",
    "We'll load the prepared GRPO dataset. If you haven't prepared it yet, run:\n",
    "```bash\n",
    "python prepare_grpo_dataset.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25958509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# Path to prepared dataset\n",
    "data_dir = Path(\"./data\")\n",
    "train_dataset_path = data_dir / \"train_hf\"\n",
    "\n",
    "print(f\"ðŸ“‚ Loading dataset from: {train_dataset_path}\")\n",
    "\n",
    "if not train_dataset_path.exists():\n",
    "    print(\"âŒ Dataset not found!\")\n",
    "    print(\"Please run: python prepare_grpo_dataset.py\")\n",
    "    print(\"This will convert your merged AMR dataset to GRPO format.\")\n",
    "else:\n",
    "    train_dataset = load_from_disk(str(train_dataset_path))\n",
    "    print(f\"âœ… Loaded {len(train_dataset)} training examples\")\n",
    "    \n",
    "    # Show dataset structure\n",
    "    print(f\"\\nðŸ“‹ Dataset columns: {train_dataset.column_names}\")\n",
    "    \n",
    "    # Show example\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Example Training Instance:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    example = train_dataset[0]\n",
    "    print(f\"\\nðŸ“ Prompt (first 300 chars):\")\n",
    "    print(example['prompt'][:300] + \"...\")\n",
    "    print(f\"\\nâœ¨ Reference (first 200 chars):\")\n",
    "    print(example['reference'][:200] + \"...\")\n",
    "    print(f\"\\nðŸ·ï¸  Task Type: {example.get('task_type', 'unknown')}\")\n",
    "    print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d92281",
   "metadata": {},
   "source": [
    "## 4. Load Model and Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50238d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer with Unsloth (optimized for speed and memory)\n",
    "print(f\"ðŸ”„ Loading model: {MODEL_NAME}\")\n",
    "print(f\"This may take a few minutes on first run...\")\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=MODEL_NAME,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    dtype=None,  # Auto-detect dtype\n",
    "    load_in_4bit=LOAD_IN_4BIT,\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Model and tokenizer loaded successfully!\")\n",
    "print(f\"   Model: {MODEL_NAME}\")\n",
    "print(f\"   Max sequence length: {MAX_SEQ_LENGTH}\")\n",
    "print(f\"   4-bit quantization: {LOAD_IN_4BIT}\")\n",
    "print(f\"   Vocab size: {len(tokenizer)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2530a7aa",
   "metadata": {},
   "source": [
    "## 5. API-Integrated Reward Model\n",
    "\n",
    "This reward model integrates with your Supabase Edge Function to evaluate model outputs using LLM-as-a-Judge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc304a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add LoRA adapters with Unsloth (super fast!)\n",
    "print(\"ðŸ”§ Adding LoRA adapters with Unsloth optimization...\")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=LORA_R,\n",
    "    target_modules=LORA_TARGET_MODULES,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… LoRA adapters added successfully!\")\n",
    "print(\"\\nðŸ“Š Trainable Parameters:\")\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class APIIntegratedRewardModel:\n",
    "    \"\"\"\n",
    "    Reward model that integrates with Supabase Edge Function for evaluation.\n",
    "    \n",
    "    Features:\n",
    "    - Async batch processing with concurrency control\n",
    "    - Response caching to avoid duplicate API calls\n",
    "    - Retry logic with exponential backoff\n",
    "    - Priority metrics mode for faster training\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        api_base_url: str,\n",
    "        metrics: List[str],\n",
    "        weights: Dict[str, float],\n",
    "        api_config: Dict[str, Any],\n",
    "        use_cache: bool = True\n",
    "    ):\n",
    "        self.api_base_url = api_base_url\n",
    "        self.metrics = metrics\n",
    "        self.weights = weights\n",
    "        self.api_config = api_config\n",
    "        self.use_cache = use_cache\n",
    "        \n",
    "        self.cache = {} if use_cache else None\n",
    "        self.stats = {\n",
    "            'total_calls': 0,\n",
    "            'cache_hits': 0,\n",
    "            'api_errors': 0,\n",
    "            'total_api_time': 0.0\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… Reward Model initialized with {len(metrics)} metrics\")\n",
    "        print(f\"   Metrics: {metrics}\")\n",
    "        print(f\"   Caching: {'Enabled' if use_cache else 'Disabled'}\")\n",
    "    \n",
    "    def _create_cache_key(self, context: Dict, model_output: str, ground_truth: str) -> str:\n",
    "        \"\"\"Create a unique cache key for an API call.\"\"\"\n",
    "        content = f\"{json.dumps(context)}|{model_output}|{ground_truth}\"\n",
    "        return hashlib.md5(content.encode()).hexdigest()\n",
    "    \n",
    "    async def _call_api_async(\n",
    "        self,\n",
    "        session: aiohttp.ClientSession,\n",
    "        context: Dict,\n",
    "        model_output: str,\n",
    "        ground_truth: str,\n",
    "        retry_count: int = 0\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Make async API call to evaluation endpoint.\"\"\"\n",
    "        \n",
    "        # Check cache\n",
    "        if self.use_cache:\n",
    "            cache_key = self._create_cache_key(context, model_output, ground_truth)\n",
    "            if cache_key in self.cache:\n",
    "                self.stats['cache_hits'] += 1\n",
    "                return self.cache[cache_key]\n",
    "        \n",
    "        # Prepare request\n",
    "        payload = {\n",
    "            \"patient_case\": context,\n",
    "            \"model_output\": model_output,\n",
    "            \"ground_truth\": ground_truth,\n",
    "            \"metrics\": self.metrics\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            async with session.post(\n",
    "                self.api_base_url,\n",
    "                json=payload,\n",
    "                timeout=aiohttp.ClientTimeout(total=self.api_config['timeout_seconds'])\n",
    "            ) as response:\n",
    "                elapsed = time.time() - start_time\n",
    "                self.stats['total_api_time'] += elapsed\n",
    "                self.stats['total_calls'] += 1\n",
    "                \n",
    "                if response.status == 200:\n",
    "                    result = await response.json()\n",
    "                    \n",
    "                    # Cache the result\n",
    "                    if self.use_cache:\n",
    "                        self.cache[cache_key] = result\n",
    "                    \n",
    "                    return result\n",
    "                else:\n",
    "                    error_text = await response.text()\n",
    "                    raise Exception(f\"API returned status {response.status}: {error_text}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Retry logic\n",
    "            if retry_count < self.api_config['max_retries']:\n",
    "                await asyncio.sleep(self.api_config['retry_delay'] * (2 ** retry_count))\n",
    "                return await self._call_api_async(\n",
    "                    session, context, model_output, ground_truth, retry_count + 1\n",
    "                )\n",
    "            else:\n",
    "                self.stats['api_errors'] += 1\n",
    "                # Return default low scores\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"evaluations\": {metric: {\"score\": 1} for metric in self.metrics},\n",
    "                    \"weighted_reward\": 0.0\n",
    "                }\n",
    "    \n",
    "    async def _evaluate_batch_async(\n",
    "        self,\n",
    "        contexts: List[Dict],\n",
    "        generated: List[str],\n",
    "        references: List[str]\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Evaluate a batch of generations using async API calls.\"\"\"\n",
    "        semaphore = asyncio.Semaphore(self.api_config['max_concurrent_requests'])\n",
    "        \n",
    "        async def evaluate_single(ctx, gen, ref):\n",
    "            async with semaphore:\n",
    "                async with aiohttp.ClientSession() as session:\n",
    "                    return await self._call_api_async(session, ctx, gen, ref)\n",
    "        \n",
    "        tasks = [\n",
    "            evaluate_single(ctx, gen, ref)\n",
    "            for ctx, gen, ref in zip(contexts, generated, references)\n",
    "        ]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def evaluate_batch(\n",
    "        self,\n",
    "        contexts: List[Dict],\n",
    "        generated: List[str],\n",
    "        references: List[str]\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Synchronous wrapper for batch evaluation.\"\"\"\n",
    "        loop = asyncio.get_event_loop()\n",
    "        return loop.run_until_complete(\n",
    "            self._evaluate_batch_async(contexts, generated, references)\n",
    "        )\n",
    "    \n",
    "    def compute_batch_rewards(\n",
    "        self,\n",
    "        contexts: List[Dict],\n",
    "        generated: List[str],\n",
    "        references: List[str]\n",
    "    ) -> Tuple[List[float], List[Dict]]:\n",
    "        \"\"\"Compute rewards for a batch of generations.\"\"\"\n",
    "        results = self.evaluate_batch(contexts, generated, references)\n",
    "        \n",
    "        rewards = []\n",
    "        all_scores = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result.get(\"success\", False):\n",
    "                reward = result.get(\"weighted_reward\", 0.0)\n",
    "                scores = result.get(\"evaluations\", {})\n",
    "            else:\n",
    "                reward = 0.0\n",
    "                scores = {}\n",
    "            \n",
    "            rewards.append(reward)\n",
    "            all_scores.append(scores)\n",
    "        \n",
    "        return rewards, all_scores\n",
    "    \n",
    "    def print_stats(self):\n",
    "        \"\"\"Print cache and API usage statistics.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Reward Model Statistics\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Total API calls: {self.stats['total_calls']}\")\n",
    "        print(f\"Cache hits: {self.stats['cache_hits']}\")\n",
    "        if self.stats['total_calls'] > 0:\n",
    "            cache_rate = (self.stats['cache_hits'] / (self.stats['total_calls'] + self.stats['cache_hits'])) * 100\n",
    "            print(f\"Cache hit rate: {cache_rate:.1f}%\")\n",
    "        print(f\"API errors: {self.stats['api_errors']}\")\n",
    "        if self.stats['total_calls'] > 0:\n",
    "            avg_time = self.stats['total_api_time'] / self.stats['total_calls']\n",
    "            print(f\"Average API call time: {avg_time:.2f}s\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# Initialize reward model\n",
    "metrics_to_use = PRIORITY_METRICS if GRPO_CONFIG[\"use_priority_metrics\"] else ALL_METRICS\n",
    "\n",
    "reward_model = APIIntegratedRewardModel(\n",
    "    api_base_url=API_BASE_URL,\n",
    "    metrics=metrics_to_use,\n",
    "    weights=REWARD_WEIGHTS,\n",
    "    api_config=API_CONFIG,\n",
    "    use_cache=API_CONFIG[\"use_cache\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Using metrics: {metrics_to_use}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
